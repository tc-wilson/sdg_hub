{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown Table Manipulation Skills\n",
    "\n",
    "Modern enterprises rely on structured data to drive decisions across operations, HR, product, and sales. But real-world data is rarely clean. Tables are often inconsistent, incomplete, or split across sources. Analysts and engineers spend countless hours fixing formatting issues, merging data, and applying business logic manually.\n",
    "\n",
    "This project teaches a language model how to understand, clean, manipulate, and reason over markdown tables‚Äîturning messy or fragmented tabular inputs into clean, analysis-ready markdown outputs that can be dropped into dashboards, reports, or downstream systems.\n",
    "\n",
    "We do this using InstructLab, by providing examples of real-world table tasks that require reasoning, formatting precision, and consistency.\n",
    "\n",
    "\n",
    "These tasks develop a model‚Äôs capabilities in:\n",
    "* Cleaning: Normalize inconsistent entries (e.g., ‚ÄúUSA‚Äù, ‚ÄúU.S.‚Äù, ‚ÄúUnited States‚Äù ‚Üí ‚ÄúUS‚Äù)\n",
    "* Filtering: Apply multi-column conditions (e.g., Progress < 60% and Budget < 100k)\n",
    "* Computation: Derive new columns from formulas (e.g., Adjusted Revenue = Revenue √ó Multiplier)\n",
    "* Joining: Merge data from multiple markdown tables using a shared key\n",
    "* Classification: Infer labels like ‚ÄúSeniority‚Äù from unstructured title strings\n",
    "* Standardization: Enforce markdown formatting, column consistency, and data integrity\n",
    "\n",
    "\n",
    "Task Examples Include:\n",
    "1.\tApplying Rules Across Columns\n",
    "\n",
    "    Derive new columns by applying conditional logic to existing data. Examples include assigning statuses, flags, or labels based on thresholds, categories, or rule-based formulas.\n",
    "\n",
    "2.  Cleaning and Normalizing Tabular Data\n",
    "\n",
    "    Standardize inconsistent entries such as location names, department labels, or text casing to ensure consistency across rows‚Äîessential for reliable analysis or joins.\n",
    "\n",
    "3. \tInferring Categorical Labels from Text\n",
    "    \n",
    "    Extract or classify values (e.g., seniority, department type, status) from semi-structured strings using pattern recognition or keyword-based inference.\n",
    "\n",
    "4. \tMerging and Enriching Data Across Tables\n",
    "    \n",
    "    Perform relational joins using keys like ID or Region, and enhance the dataset by combining fields from multiple sources.\n",
    "\n",
    "5.  Retrieval and Filtering From the Table\n",
    "\n",
    "    Retrieve specific rows or columns based on conditions or patterns, useful for ad-hoc queries or filtering out irrelevant data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßë‚Äçüè´ Step 1: Set Up the Teacher Model\n",
    "\n",
    "This demo expects an openai compatible endpoint. You can use your favorite inference server like vLLM, HFInferenceServer, LlamaStack, etc. For more details on how to setup an inference server using vLLM, please refer to the [README](README.md).\n",
    "\n",
    "For this demo we will use Llama-3.3-70B-Instruct as our teacher model.\n",
    "\n",
    "#### Let's test the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful! meta-llama/Llama-3.3-70B-Instruct: Hello. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = \"EMPTY\" # replace with your inference server api key\n",
    "openai_api_base = \"http://0.0.0.0:8000/v1\" # replace with your inference server endpoint\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "teacher_model = models.data[0].id\n",
    "\n",
    "# Test the connection with a simple completion\n",
    "response = client.chat.completions.create(\n",
    "    model=teacher_model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "    temperature=0.0,\n",
    "    max_tokens=10\n",
    ")\n",
    "completion = response.choices[0].message.content\n",
    "\n",
    "print(f\"Connection successful! {teacher_model}: {completion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Step 2: Provide Custom Examples\n",
    "\n",
    "As outlined in the LAB paper, the first step is to provide a small number of **seed examples** (typically 5) to bootstrap the skill. These examples are passed into the generation pipeline as input and are stored in a `.jsonl` file.\n",
    "\n",
    "For this demo, we‚Äôll use the pre-populated seed file located at: [mdtable_manipulation_seeds.jsonl](examples/instructlab/skills/sample_data/mdtable_manipulation_seeds.jsonl)\n",
    "\n",
    "Lets open the file and explore a row: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the seed dataset\n",
    "seed_data = load_dataset(\"json\", data_files=\"sample_data/mdtable_manipulation_seeds.jsonl\", split=\"train\")\n",
    "\n",
    "# Display the first example\n",
    "seed_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "```\n",
    "{'task_description': 'Perform advanced table manipulation, including cleaning, joining, inferring values, and computing derived columns based on complex rules.',\n",
    " 'seed_question': '| Project | Budget (USD) | Progress (%) | Phase     |\\n|---------|--------------|--------------|-----------|\\n| Mercury | 120000       | 85           | Alpha     |\\n| Venus   | 95000        | 78           | Alpha     |\\n| Earth   | 87000        | 52           | Beta      |\\n| Mars    | 110000       | 45           | Beta      |\\n| Jupiter | 78000        | 66           | Gamma     |\\n\\nQuestion: Add a new column \\'Status\\' using these rules:\\n- If Budget > 100k and Progress ‚â• 80%, mark as \"On Track\"\\n- If Budget < 100k but Progress ‚â• 60%, mark as \"Risk: Underfunded\"\\n- If Progress < 60%, mark as \"Behind\"',\n",
    " 'seed_response': '| Project | Budget (USD) | Progress (%) | Phase | Status            |\\n|---------|--------------|--------------|--------|-------------------|\\n| Mercury | 120000       | 85           | Alpha | On Track          |\\n| Venus   | 95000        | 78           | Alpha | Risk: Underfunded |\\n| Earth   | 87000        | 52           | Beta  | Behind            |\\n| Mars    | 110000       | 45           | Beta  | Behind            |\\n| Jupiter | 78000        | 66           | Gamma | Risk: Underfunded |'}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seed_data[0][\"seed_question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "| Project | Budget (USD) | Progress (%) | Phase     |\n",
    "|---------|--------------|--------------|-----------|\n",
    "| Mercury | 120000       | 85           | Alpha     |\n",
    "| Venus   | 95000        | 78           | Alpha     |\n",
    "| Earth   | 87000        | 52           | Beta      |\n",
    "| Mars    | 110000       | 45           | Beta      |\n",
    "| Jupiter | 78000        | 66           | Gamma     |\n",
    "\n",
    "Question: Add a new column 'Status' using these rules:\n",
    "- If Budget > 100k and Progress ‚â• 80%, mark as \"On Track\"\n",
    "- If Budget < 100k but Progress ‚â• 60%, mark as \"Risk: Underfunded\"\n",
    "- If Progress < 60%, mark as \"Behind\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 3: Generate Synthetic Data\n",
    "\n",
    "Now that we have our seed data ready, we can use LAB‚Äôs Skill Data Generator to create **high-quality synthetic training examples** for our custom skill.\n",
    "\n",
    "This step leverages a predefined **flow configuration** that encodes how seed examples are expanded ‚Äî by generating new contexts, questions, and responses, and filtering them for quality.\n",
    "\n",
    "In this demo, we'll use the `synth_skills.yaml` flow, which follows LAB's grounded generation pattern (question ‚Üí response)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdg_hub.flow import Flow\n",
    "from sdg_hub.pipeline import Pipeline\n",
    "from sdg_hub.sdg import SDG\n",
    "\n",
    "# Path to the skill generation flow configuration\n",
    "flow_path = \"flows/synth_skills.yaml\"\n",
    "\n",
    "# Load the flow\n",
    "flow = Flow(client).get_flow_from_file(flow_path)\n",
    "\n",
    "# Initialize the synthetic data generator\n",
    "generator = SDG(\n",
    "    [Pipeline(flow)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the generator is ready to run the full pipeline ‚Äî including context generation, question/response generation, evaluation, and filtering ‚Äî to produce a synthetic dataset that can be used for fine-tuning or skill bootstrapping.\n",
    "\n",
    "In the next step, we‚Äôll run this pipeline and inspect the generated outputs. \n",
    "\n",
    "> ‚ö†Ô∏è Note: This would take a variable amount of time depending on the hardware used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = generator.generate(seed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 4: Explore and Validate the Synthetically Generated Data\n",
    "\n",
    "Once the skill generation pipeline has been executed, the output is a set of **synthetically generated examples** ‚Äî new context-question-response triples that follow the same structure as the seed data but are expanded and refined by the teacher model.\n",
    "\n",
    "Below is an example of one generated entry:\n",
    "\n",
    "> ‚ö†Ô∏è Note: You might not get the same expected output as the one below because the generation is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "rand_idx = random.choice(range(len(generated_data)))\n",
    "generated_data[rand_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "\n",
    "```\n",
    "{'task_description': 'Perform advanced table manipulation, including cleaning, joining, inferring values, and computing derived columns based on complex rules.',\n",
    " 'seed_question': '| Name         | Role Title                  |\\n|--------------|-----------------------------|\\n| Nia Kapoor   | Lead Software Engineer      |\\n| Omar Ghali   | UX Designer                 |\\n| Lin Zhu      | Intern - AI Research        |\\n| Carlos Pena  | Data Specialist             |\\n| Tessa Morgan | Principal Product Manager   |\\n\\nQuestion: Add a column called \\'Seniority\\' where:\\n- Titles with \\'Lead\\', \\'Principal\\', or \\'Head\\' ‚Üí \"Senior\"\\n- Titles with \\'Engineer\\', \\'Specialist\\', \\'Designer\\', or \\'Analyst\\' ‚Üí \"Mid\"\\n- Titles with \\'Intern\\' or \\'Trainee\\' ‚Üí \"Junior\"',\n",
    " 'seed_response': '| Name         | Role Title                  | Seniority |\\n|--------------|-----------------------------|-----------|\\n| Nia Kapoor   | Lead Software Engineer      | Senior    |\\n| Omar Ghali   | UX Designer                 | Mid       |\\n| Lin Zhu      | Intern - AI Research        | Junior    |\\n| Carlos Pena  | Data Specialist             | Mid       |\\n| Tessa Morgan | Principal Product Manager   | Senior    |',\n",
    " 'question': '| Student ID | Name         | Grade | GPA |\\n|------------|--------------|-------|-----|\\n| 1          | Emily Chen   | 10    | 3.8 |\\n| 2          | David Lee    | 11    | 3.5 |\\n| 3          | Sophia Patel | 12    | 3.9 |\\n| 4          | Jackson Kim  | 10    | 3.2 |\\n| 5          | Olivia Brown | 11    | 3.6 |\\n\\nQuestion: Create a new column called \\'Academic Status\\' where:\\n- GPA greater than 3.7 ‚Üí \"Honors\"\\n- GPA between 3.3 and 3.7 ‚Üí \"Passing\"\\n- GPA less than 3.3 ‚Üí \"Probation\"',\n",
    " 'response': '| Student ID | Name         | Grade | GPA | Academic Status |\\n|------------|--------------|-------|-----|-----------------|\\n| 1          | Emily Chen   | 10    | 3.8 | Honors          |\\n| 2          | David Lee    | 11    | 3.5 | Passing         |\\n| 3          | Sophia Patel | 12    | 3.9 | Honors          |\\n| 4          | Jackson Kim  | 10    | 3.2 | Probation       |\\n| 5          | Olivia Brown | 11    | 3.6 | Passing         |'}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated_data[rand_idx]['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "| Student ID | Name         | Grade | GPA |\n",
    "|------------|--------------|-------|-----|\n",
    "| 1          | Emily Chen   | 10    | 3.8 |\n",
    "| 2          | David Lee    | 11    | 3.5 |\n",
    "| 3          | Sophia Patel | 12    | 3.9 |\n",
    "| 4          | Jackson Kim  | 10    | 3.2 |\n",
    "| 5          | Olivia Brown | 11    | 3.6 |\n",
    "\n",
    "Question: Create a new column called 'Academic Status' where:\n",
    "- GPA greater than 3.7 ‚Üí \"Honors\"\n",
    "- GPA between 3.3 and 3.7 ‚Üí \"Passing\"\n",
    "- GPA less than 3.3 ‚Üí \"Probation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated_data[rand_idx]['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "\n",
    "\n",
    "| Student ID | Name         | Grade | GPA | Academic Status |\n",
    "|------------|--------------|-------|-----|-----------------|\n",
    "| 1          | Emily Chen   | 10    | 3.8 | Honors          |\n",
    "| 2          | David Lee    | 11    | 3.5 | Passing         |\n",
    "| 3          | Sophia Patel | 12    | 3.9 | Honors          |\n",
    "| 4          | Jackson Kim  | 10    | 3.2 | Probation       |\n",
    "| 5          | Olivia Brown | 11    | 3.6 | Passing         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÅ Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to teach a custom skill to a language model using the InstructLab Skill Data Generator (SDG). Starting from a small set of seed examples, we walked through the full synthetic data generation pipeline ‚Äî including context creation, question generation, response synthesis, evaluation, and filtering.\n",
    "\n",
    "We explored a real-world use case: **Manipulating Markdown Tables**, and showed how the LAB framework can automate the generation of high-quality, instructional training data at scale.\n",
    "\n",
    "This approach is especially powerful for procedural or domain-specific tasks where labeled data is scarce but consistent task logic can be modeled. With just a few carefully curated seed examples, you can unlock scalable skill creation and push new capabilities into LLMs with minimal manual effort.\n",
    "\n",
    "You‚Äôre now ready to use these synthetic examples for Fine-tuning small models! \n",
    "\n",
    "Next steps? \n",
    "\n",
    "* Try changing the parameters of the flow to see how the generated data changes (e.g. change the `num_samples` or try generating with different temperature)\n",
    "* Try adapting this pipeline to your own task, domain, or format ‚Äî whether it‚Äôs triaging support tickets, extracting structured data, or following domain-specific workflows. The skills are yours to create."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg_hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
